{
  "fin": {
    "precision": 0.3,
    "recall": 0.23076923076923078,
    "f1-score": 0.2608695652173913,
    "support": 13,
    "confused_with": {
      "incomp": 5,
      "greet": 2
    }
  },
  "descrip": {
    "precision": 0.5714285714285714,
    "recall": 0.6666666666666666,
    "f1-score": 0.6153846153846153,
    "support": 30,
    "confused_with": {
      "prix": 6,
      "ask_retour": 2
    }
  },
  "dispo": {
    "precision": 1.0,
    "recall": 0.2857142857142857,
    "f1-score": 0.4444444444444445,
    "support": 7,
    "confused_with": {
      "descrip": 2,
      "incomp": 1
    }
  },
  "ask_local": {
    "precision": 0.375,
    "recall": 0.42857142857142855,
    "f1-score": 0.39999999999999997,
    "support": 7,
    "confused_with": {
      "incomp": 1,
      "greet": 1
    }
  },
  "incomp": {
    "precision": 0.5945945945945946,
    "recall": 0.5945945945945946,
    "f1-score": 0.5945945945945946,
    "support": 37,
    "confused_with": {
      "greet": 8,
      "fin": 3
    }
  },
  "greet": {
    "precision": 0.4074074074074074,
    "recall": 0.5789473684210527,
    "f1-score": 0.47826086956521735,
    "support": 19,
    "confused_with": {
      "incomp": 6,
      "fin": 1
    }
  },
  "ask_general": {
    "precision": 0.5,
    "recall": 0.2,
    "f1-score": 0.28571428571428575,
    "support": 5,
    "confused_with": {
      "descrip": 2,
      "prix": 1,
      "exist": 1
    }
  },
  "ask_retour": {
    "precision": 0.5882352941176471,
    "recall": 0.5882352941176471,
    "f1-score": 0.5882352941176471,
    "support": 17,
    "confused_with": {
      "command": 3,
      "fin": 2
    }
  },
  "ask_livraison": {
    "precision": 1.0,
    "recall": 0.14285714285714285,
    "f1-score": 0.25,
    "support": 7,
    "confused_with": {
      "prix": 3,
      "descrip": 2,
      "greet": 1
    }
  },
  "exist": {
    "precision": 0.6,
    "recall": 0.46153846153846156,
    "f1-score": 0.5217391304347826,
    "support": 13,
    "confused_with": {
      "descrip": 3,
      "prix": 1
    }
  },
  "prix": {
    "precision": 0.6206896551724138,
    "recall": 0.782608695652174,
    "f1-score": 0.6923076923076923,
    "support": 23,
    "confused_with": {
      "greet": 3,
      "descrip": 1
    }
  },
  "command": {
    "precision": 0.75,
    "recall": 0.75,
    "f1-score": 0.75,
    "support": 12,
    "confused_with": {
      "ask_retour": 2,
      "incomp": 1
    }
  },
  "accuracy": 0.5578947368421052,
  "macro avg": {
    "precision": 0.6089462935600528,
    "recall": 0.4758752640752237,
    "f1-score": 0.49012920764838924,
    "support": 190
  },
  "weighted avg": {
    "precision": 0.5841287365924389,
    "recall": 0.5578947368421052,
    "f1-score": 0.545974565734291,
    "support": 190
  }
}